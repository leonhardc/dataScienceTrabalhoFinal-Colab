{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trabalho-final-acidentes-de-transitov2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9ZcObhaiOeo5",
        "sIQE_bp2OmWc",
        "MMZsKnu5kfWX",
        "_6f393c1zDFI",
        "XomTgBSp2zsJ",
        "6vsMhW_92KnZ"
      ],
      "mount_file_id": "1bspK49SGjD6buqFUGVtTfo6UAyUFy7PE",
      "authorship_tag": "ABX9TyNdQslsrXB4k76kPOyNU7ly",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leonhardc/dataScienceTrabalhoFinal-Colab/blob/master/Trabalho_final_acidentes_de_transitov2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvTKLkDezhSt"
      },
      "source": [
        "# Etapa Scrub e Explore\n",
        "\n",
        "O intuito dessa codificação foi processar os dados obtidos na etapa anterior, dados esses cedidos pelo professor. \n",
        "Aqui foram aplicados filtros relevantes como, filtros de linhas nulas e linhas repetidas, além de filtros de UF, para selecionar todos os dados somente relacionados com o estado do ceará. Também foi feita uma exploração dos dados, como números de mortos a cada ano, a cidade mais frequente em acidentes a cada ano, e numeros de feridos graves. \n",
        "\n",
        "\n",
        "Os dados dos quatro datasets selecionados foram concatenados em um unico arquivo, o que facilita processamento futuro. \n",
        "\n",
        "OBS: Para que as células executem, é necessário gerar o código e adicionar o caminho do seu drive que contém os arquivos  de acidentes de transito de 2017 a 2020."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ehnZBxaOTN3"
      },
      "source": [
        "##### Importações"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw8sALFGNFci"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "from google.colab import drive "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZcObhaiOeo5"
      },
      "source": [
        "##### Montar o Google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCxy9WXSN_lH"
      },
      "source": [
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIQE_bp2OmWc"
      },
      "source": [
        "##### Importar csv como dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1Zj-qIHOts9"
      },
      "source": [
        "df2017 = pd.read_csv('/content/drive/My Drive/DataScienceDataSet/_originais/acidentes2017_todas_causas_tipos.csv', sep=';')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT2CaYRq0-IT"
      },
      "source": [
        "df2018 = pd.read_csv('/content/drive/My Drive/DataScienceDataSet/_originais/acidentes2018_todas_causas_tipos.csv', sep=';')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20ymiEU00-nT"
      },
      "source": [
        "df2019 = pd.read_csv('/content/drive/My Drive/DataScienceDataSet/_originais/acidentes2019_todas_causas_tipos.csv', sep=';')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZnVjk5R0--Q"
      },
      "source": [
        "df2020 = pd.read_csv('/content/drive/My Drive/DataScienceDataSet/_originais/acidentes2020_todas_causas_tipos.csv', sep=';')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMZsKnu5kfWX"
      },
      "source": [
        "##### Informações"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z4UkpZtkABU"
      },
      "source": [
        "df2017.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYcDpqwVkD_E"
      },
      "source": [
        "df2018.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Miiu8OJEkEp0"
      },
      "source": [
        "df2019.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL1bG51GkFaB"
      },
      "source": [
        "df2020.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6f393c1zDFI"
      },
      "source": [
        "#### Aplicando filtros "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfXTqbd_2aWv"
      },
      "source": [
        "##### Remoção das linhas com valores faltantes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfuNzeiZkwn0"
      },
      "source": [
        "# Nesse passo, basicamente, estou removendo todas as linhas com, pelo menos um valor faltante em todos os dataframes\n",
        "\n",
        "df2017.dropna(inplace=True) \n",
        "df2018.dropna(inplace=True)\n",
        "df2019.dropna(inplace=True)\n",
        "df2020.dropna(inplace=True)\n",
        "\n",
        "# Logo após, exibirmos as informações dos dataframes para observar se alguma mudança foi feita\n",
        "\n",
        "print(\"DataFrame2017: \" + str(df2017.shape)) # exibe quantidade de linhas e colunas do dataframe\n",
        "print(\"DataFrame2018: \" + str(df2018.shape))\n",
        "print(\"DataFrame2019: \" + str(df2019.shape))\n",
        "print(\"DataFrame2020: \" + str(df2020.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTZpQ5C62kZu"
      },
      "source": [
        "##### Remoção de atributos irrelevantes para o que se deseja fazer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayhNspVbzKkm"
      },
      "source": [
        "# Atributos que se deseja excluir\n",
        "atrib = ['feridos_leves','ilesos','latitude', 'longitude', 'pesid', 'horario', 'br', 'km', 'causa_principal', 'causa_acidente', 'ordem_tipo_acidente', 'fase_dia', 'sentido_via', 'condicao_metereologica', 'tipo_pista', 'tracado_via','uso_solo', 'id_veiculo', 'tipo_veiculo', 'marca', 'ano_fabricacao_veiculo', 'regional', 'delegacia', 'uop']\n",
        "\n",
        "for a in atrib:\n",
        "  df2017 = df2017.drop(a, axis = 1)\n",
        "  df2018 = df2018.drop(a, axis = 1)\n",
        "  df2019 = df2019.drop(a, axis = 1)\n",
        "  df2020 = df2020.drop(a, axis = 1)\n",
        "\n",
        "print(\"DataFrame2017: \" + str(df2017.shape)) # exibe quantidade de linhas e colunas do dataframe\n",
        "print(\"DataFrame2018: \" + str(df2018.shape))\n",
        "print(\"DataFrame2019: \" + str(df2019.shape))\n",
        "print(\"DataFrame2020: \" + str(df2020.shape))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_eyZzPn2v3c"
      },
      "source": [
        "##### Remoção de linhas duplicadas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASDDcFamtKMW"
      },
      "source": [
        "# Primeiramente, vamos verificar e excluir quaisquer linhas duplicadas\n",
        "\n",
        "df2017.drop_duplicates()\n",
        "df2018.drop_duplicates()\n",
        "df2019.drop_duplicates()\n",
        "df2020.drop_duplicates()\n",
        "\n",
        "print(\"DataFrame2017: \" + str(df2017.shape)) # exibe quantidade de linhas e colunas do dataframe\n",
        "print(\"DataFrame2018: \" + str(df2018.shape))\n",
        "print(\"DataFrame2019: \" + str(df2019.shape))\n",
        "print(\"DataFrame2020: \" + str(df2020.shape))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAAGkyMnmB7U"
      },
      "source": [
        "##### Aplicar filtros, referentes a seleção do estado do Ceará"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzPL5M5DmSLm"
      },
      "source": [
        "# filtro de uf, somente para o ceará\n",
        "newindex = list(range(0, len(df2017)))\n",
        "df2017.index = newindex\n",
        "\n",
        "dftemp = pd.DataFrame(columns=df2017.columns, index = df2017.index)\n",
        "\n",
        "for a in df2017.index:\n",
        "  if df2017['uf'][a] == 'CE':\n",
        "   pd.DataFrame(np.insert(dftemp.values, a, df2017.values[a], axis=0)) #Cria espaço \n",
        "   dftemp.values[a] = df2017.values[a]\n",
        "   print(dftemp.values[a])\n",
        "\n",
        "# tratamento de espaços vazios\n",
        "dftemp.dropna(inplace=True) #Apagando todas as linhas com espaços vazios\n",
        "newindex = list(range(0, len(dftemp)))\n",
        "dftemp.index = newindex #Recolocando os indices do dataframe\n",
        "\n",
        "\n",
        "df2017 = dftemp\n",
        "print(\"DataFrame2017: \" + str(df2017.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMXWxRIWp8MZ"
      },
      "source": [
        "newindex = list(range(0, len(df2018)))\n",
        "df2018.index = newindex\n",
        "\n",
        "dftemp = pd.DataFrame(columns=df2018.columns, index = df2018.index)\n",
        "\n",
        "for a in df2018.index:\n",
        "  if df2018['uf'][a] == 'CE':\n",
        "   pd.DataFrame(np.insert(dftemp.values, a, df2018.values[a], axis=0)) #Cria espaço \n",
        "   dftemp.values[a] = df2018.values[a]\n",
        "   print(dftemp.values[a])\n",
        "\n",
        "# tratamento de espaços vazios\n",
        "dftemp.dropna(inplace=True) #Apagando todas as linhas com espaços vazios\n",
        "newindex = list(range(0, len(dftemp)))\n",
        "dftemp.index = newindex #Recolocando os indices do dataframe\n",
        "\n",
        "\n",
        "df2018 = dftemp\n",
        "print(\"DataFrame2018: \" + str(df2018.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qY8Qc9CcqCHc"
      },
      "source": [
        "newindex = list(range(0, len(df2019)))\n",
        "df2019.index = newindex\n",
        "\n",
        "dftemp = pd.DataFrame(columns=df2019.columns, index = df2019.index)\n",
        "\n",
        "for a in df2019.index:\n",
        "  if df2019['uf'][a] == 'CE':\n",
        "   pd.DataFrame(np.insert(dftemp.values, a, df2019.values[a], axis=0)) #Cria espaço \n",
        "   dftemp.values[a] = df2019.values[a]\n",
        "   print(dftemp.values[a])\n",
        "\n",
        "# tratamento de espaços vazios\n",
        "dftemp.dropna(inplace=True) #Apagando todas as linhas com espaços vazios\n",
        "newindex = list(range(0, len(dftemp)))\n",
        "dftemp.index = newindex #Recolocando os indices do dataframe\n",
        "\n",
        "\n",
        "df2019 = dftemp\n",
        "print(\"DataFrame2019: \" + str(df2019.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRVFzq07qHMm"
      },
      "source": [
        "newindex = list(range(0, len(df2020)))\n",
        "df2020.index = newindex\n",
        "\n",
        "dftemp = pd.DataFrame(columns=df2020.columns, index = df2020.index)\n",
        "\n",
        "for a in df2020.index:\n",
        "  if df2020['uf'][a] == 'CE':\n",
        "   pd.DataFrame(np.insert(dftemp.values, a, df2020.values[a], axis=0)) #Cria espaço \n",
        "   dftemp.values[a] = df2020.values[a]\n",
        "   print(dftemp.values[a])\n",
        "\n",
        "# tratamento de espaços vazios\n",
        "dftemp.dropna(inplace=True) #Apagando todas as linhas com espaços vazios\n",
        "newindex = list(range(0, len(dftemp)))\n",
        "dftemp.index = newindex #Recolocando os indices do dataframe\n",
        "\n",
        "\n",
        "df2020 = dftemp\n",
        "print(\"DataFrame2020: \" + str(df2020.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XomTgBSp2zsJ"
      },
      "source": [
        "#### Concatenar dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkA6F3Hc2w96"
      },
      "source": [
        "fullDataFrame = pd.concat([df2017, df2018], ignore_index=True)\n",
        "fullDataFrame = pd.concat([fullDataFrame, df2019], ignore_index=True)\n",
        "fullDataFrame = pd.concat([fullDataFrame, df2020], ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ETAPA EXPLORE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Exibindo estatísticas básicas:média, desvio padrão, contagem de valor,mínimo, máximo e 25,50 e 75 quantis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#ano de 2017\n",
        "df2017.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ano de 2018\n",
        "df2018.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ano de 2019\n",
        "df2019.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ano de 2020\n",
        "df2020.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Exibindo os tipos de dados dos DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#ano de 2017\n",
        "df2017.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ano de 2018\n",
        "df2018.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ano de 2019\n",
        "df2019.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ano de 2020\n",
        "df2020.dtypes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#exibindo o número de feridos graves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#ano de 2017\n",
        "df2017['feridos_grave'].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ano de 2018\n",
        "df2018['feridos_grave'].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ano de 2019\n",
        "df2019['feridos_grave'].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ano de 2020\n",
        "df2020['feridos_grave'].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#exibindo números de mortos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ano de 2017\n",
        "df2017['mortos'].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ano de 2018\n",
        "df2018['mortos'].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ano de 2019\n",
        "df2019['mortos'].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ano de 2020\n",
        "df2020['mortos'].sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vsMhW_92KnZ"
      },
      "source": [
        "#### Salvar dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVhhEiua2P3V"
      },
      "source": [
        "fullDataFrame.to_csv('/content/drive/My Drive/DataScienceDataSet/_modificados/acidentes2017a2020.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}